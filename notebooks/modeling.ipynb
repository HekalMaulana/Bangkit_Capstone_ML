{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/interests_without_onehot.csv\")\n",
    "\n",
    "features = df.iloc[:, :-1].values\n",
    "labels = df[\"y\"].values\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features : tf.Tensor([0 1 0 2 1 0 0 2 0 1 0 2 0 0 1 1 0 0 2 1 0 1 2 1 1], shape=(25,), dtype=int64)\n",
      "Label: tf.Tensor(b'IT sector', shape=(), dtype=string)\n",
      "Label dtype: <dtype: 'string'>\n",
      "features : tf.Tensor([1 0 1 0 0 0 0 0 0 0 0 0 0 2 2 1 1 1 0 2 0 1 2 1 0], shape=(25,), dtype=int64)\n",
      "Label: tf.Tensor(b'IT sector', shape=(), dtype=string)\n",
      "Label dtype: <dtype: 'string'>\n",
      "features : tf.Tensor([2 1 2 0 0 1 2 2 0 1 2 0 0 1 2 1 0 0 2 1 0 2 0 1 1], shape=(25,), dtype=int64)\n",
      "Label: tf.Tensor(b'IT sector', shape=(), dtype=string)\n",
      "Label dtype: <dtype: 'string'>\n",
      "features : tf.Tensor([0 2 0 0 0 2 2 0 0 0 1 1 0 0 1 1 0 0 2 1 0 2 2 0 1], shape=(25,), dtype=int64)\n",
      "Label: tf.Tensor(b'IT sector', shape=(), dtype=string)\n",
      "Label dtype: <dtype: 'string'>\n",
      "features : tf.Tensor([1 1 1 1 1 1 1 1 0 1 2 1 0 1 1 1 1 1 0 1 2 1 1 1 1], shape=(25,), dtype=int64)\n",
      "Label: tf.Tensor(b'IT sector', shape=(), dtype=string)\n",
      "Label dtype: <dtype: 'string'>\n"
     ]
    }
   ],
   "source": [
    "for features, label in dataset.take(5):\n",
    "    print(\"features :\", features)\n",
    "    print(\"Label:\", label)\n",
    "    print(\"Label dtype:\", label.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = tf.constant([\"IT sector\", \"Goverment sector\", \"Health sector\", \"Education sector\", \"Sports sector\", \"Finance sector\", \"Entertainment sector\"])\n",
    "values = tf.constant([0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "table = tf.lookup.StaticHashTable(\n",
    "    initializer=tf.lookup.KeyValueTensorInitializer(keys, values),\n",
    "    default_value=-1\n",
    ")\n",
    "\n",
    "def preprocess(features, label):\n",
    "    label_int = table.lookup(label)\n",
    "    label_encoded = tf.one_hot(label_int, depth=7)\n",
    "    \n",
    "    return features, label_encoded\n",
    "\n",
    "dataset = dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Features: tf.Tensor([0 1 0 2 1 0 0 2 0 1 0 2 0 0 1 1 0 0 2 1 0 1 2 1 1], shape=(25,), dtype=int64)\n",
      "One-Hot Encoded Labels: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Original Features: tf.Tensor([1 0 1 0 0 0 0 0 0 0 0 0 0 2 2 1 1 1 0 2 0 1 2 1 0], shape=(25,), dtype=int64)\n",
      "One-Hot Encoded Labels: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Original Features: tf.Tensor([2 1 2 0 0 1 2 2 0 1 2 0 0 1 2 1 0 0 2 1 0 2 0 1 1], shape=(25,), dtype=int64)\n",
      "One-Hot Encoded Labels: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Original Features: tf.Tensor([0 2 0 0 0 2 2 0 0 0 1 1 0 0 1 1 0 0 2 1 0 2 2 0 1], shape=(25,), dtype=int64)\n",
      "One-Hot Encoded Labels: [1. 0. 0. 0. 0. 0. 0.]\n",
      "Original Features: tf.Tensor([1 1 1 1 1 1 1 1 0 1 2 1 0 1 1 1 1 1 0 1 2 1 1 1 1], shape=(25,), dtype=int64)\n",
      "One-Hot Encoded Labels: [1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for features, labels in dataset.take(5):\n",
    "    print(\"Original Features:\", features)\n",
    "    print(\"One-Hot Encoded Labels:\", labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "for feature, label in dataset:\n",
    "    features.append(feature.numpy())\n",
    "    labels.append(label.numpy())\n",
    "\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.25, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (32, 25)\n",
      "Labels shape: (32, 7)\n"
     ]
    }
   ],
   "source": [
    "for features, labels in train_dataset.take(1):\n",
    "    print(\"Features shape:\", features.shape)\n",
    "    print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(25,), kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 2s 123ms/step - loss: 2.3746 - accuracy: 0.1678 - val_loss: 2.2888 - val_accuracy: 0.2200\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 2.2676 - accuracy: 0.2349 - val_loss: 2.2062 - val_accuracy: 0.4400\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 2.2181 - accuracy: 0.2953 - val_loss: 2.1253 - val_accuracy: 0.5800\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 2.0939 - accuracy: 0.4027 - val_loss: 2.0431 - val_accuracy: 0.6200\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 2.0558 - accuracy: 0.3960 - val_loss: 1.9573 - val_accuracy: 0.6200\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.9776 - accuracy: 0.4430 - val_loss: 1.8632 - val_accuracy: 0.6400\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.9038 - accuracy: 0.4698 - val_loss: 1.7596 - val_accuracy: 0.6800\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.7356 - accuracy: 0.5839 - val_loss: 1.6305 - val_accuracy: 0.7200\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 1.6482 - accuracy: 0.6510 - val_loss: 1.4852 - val_accuracy: 0.8000\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 1.6182 - accuracy: 0.5839 - val_loss: 1.3503 - val_accuracy: 0.8200\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.4955 - accuracy: 0.6376 - val_loss: 1.2330 - val_accuracy: 0.8600\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.3572 - accuracy: 0.6510 - val_loss: 1.1280 - val_accuracy: 0.8800\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1.2050 - accuracy: 0.7517 - val_loss: 1.0205 - val_accuracy: 0.9000\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.2101 - accuracy: 0.7047 - val_loss: 0.9181 - val_accuracy: 0.9400\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 1.0757 - accuracy: 0.7919 - val_loss: 0.8333 - val_accuracy: 0.9400\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 1.0586 - accuracy: 0.7852 - val_loss: 0.7752 - val_accuracy: 0.9400\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.9711 - accuracy: 0.8121 - val_loss: 0.7212 - val_accuracy: 0.9600\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.9129 - accuracy: 0.8456 - val_loss: 0.6741 - val_accuracy: 0.9600\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.7839 - accuracy: 0.8993 - val_loss: 0.6446 - val_accuracy: 0.9600\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8489 - accuracy: 0.8255 - val_loss: 0.6161 - val_accuracy: 0.9600\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.8539 - accuracy: 0.8456 - val_loss: 0.5772 - val_accuracy: 0.9600\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.7936 - accuracy: 0.8322 - val_loss: 0.5495 - val_accuracy: 0.9600\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.7084 - accuracy: 0.8926 - val_loss: 0.5225 - val_accuracy: 0.9600\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6654 - accuracy: 0.9195 - val_loss: 0.5053 - val_accuracy: 0.9600\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.6488 - accuracy: 0.9262 - val_loss: 0.4969 - val_accuracy: 0.9600\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.6300 - accuracy: 0.9262 - val_loss: 0.4856 - val_accuracy: 0.9600\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.6335 - accuracy: 0.9195 - val_loss: 0.4675 - val_accuracy: 0.9600\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.5684 - accuracy: 0.9396 - val_loss: 0.4529 - val_accuracy: 0.9600\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5863 - accuracy: 0.8993 - val_loss: 0.4443 - val_accuracy: 0.9600\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.5499 - accuracy: 0.9463 - val_loss: 0.4407 - val_accuracy: 0.9600\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5138 - accuracy: 0.9530 - val_loss: 0.4380 - val_accuracy: 0.9600\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5101 - accuracy: 0.9597 - val_loss: 0.4354 - val_accuracy: 0.9600\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5379 - accuracy: 0.9195 - val_loss: 0.4250 - val_accuracy: 0.9600\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4826 - accuracy: 0.9530 - val_loss: 0.4113 - val_accuracy: 0.9600\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5215 - accuracy: 0.9463 - val_loss: 0.4085 - val_accuracy: 0.9600\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.4445 - accuracy: 0.9732 - val_loss: 0.4083 - val_accuracy: 0.9600\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5022 - accuracy: 0.9530 - val_loss: 0.4078 - val_accuracy: 0.9600\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4654 - accuracy: 0.9597 - val_loss: 0.4054 - val_accuracy: 0.9600\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4771 - accuracy: 0.9463 - val_loss: 0.3868 - val_accuracy: 0.9600\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4006 - accuracy: 0.9732 - val_loss: 0.3712 - val_accuracy: 0.9600\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.9530 - val_loss: 0.3714 - val_accuracy: 0.9600\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4027 - accuracy: 0.9933 - val_loss: 0.3770 - val_accuracy: 0.9600\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4342 - accuracy: 0.9530 - val_loss: 0.3783 - val_accuracy: 0.9600\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4113 - accuracy: 0.9664 - val_loss: 0.3703 - val_accuracy: 0.9600\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3979 - accuracy: 0.9732 - val_loss: 0.3611 - val_accuracy: 0.9600\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3697 - accuracy: 0.9799 - val_loss: 0.3579 - val_accuracy: 0.9600\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4158 - accuracy: 0.9463 - val_loss: 0.3587 - val_accuracy: 0.9600\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.9799 - val_loss: 0.3629 - val_accuracy: 0.9600\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3806 - accuracy: 0.9530 - val_loss: 0.3535 - val_accuracy: 0.9600\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3942 - accuracy: 0.9664 - val_loss: 0.3443 - val_accuracy: 0.9600\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3689 - accuracy: 0.9799 - val_loss: 0.3396 - val_accuracy: 0.9600\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3853 - accuracy: 0.9463 - val_loss: 0.3435 - val_accuracy: 0.9600\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.9664 - val_loss: 0.3494 - val_accuracy: 0.9600\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3576 - accuracy: 0.9732 - val_loss: 0.3526 - val_accuracy: 0.9600\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3313 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9600\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3768 - accuracy: 0.9597 - val_loss: 0.3447 - val_accuracy: 0.9600\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3766 - accuracy: 0.9597 - val_loss: 0.3420 - val_accuracy: 0.9600\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3440 - accuracy: 0.9664 - val_loss: 0.3386 - val_accuracy: 0.9600\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2990 - accuracy: 0.9933 - val_loss: 0.3379 - val_accuracy: 0.9600\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2968 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9600\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2942 - accuracy: 0.9866 - val_loss: 0.3173 - val_accuracy: 0.9600\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2973 - accuracy: 0.9732 - val_loss: 0.3176 - val_accuracy: 0.9600\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.3114 - accuracy: 0.9799 - val_loss: 0.3203 - val_accuracy: 0.9600\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3111 - accuracy: 0.9664 - val_loss: 0.3100 - val_accuracy: 0.9600\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3078 - accuracy: 0.9799 - val_loss: 0.3016 - val_accuracy: 0.9600\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2863 - accuracy: 1.0000 - val_loss: 0.2984 - val_accuracy: 0.9600\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2710 - accuracy: 0.9933 - val_loss: 0.3029 - val_accuracy: 0.9600\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2874 - accuracy: 0.9866 - val_loss: 0.3040 - val_accuracy: 0.9600\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2781 - accuracy: 0.9933 - val_loss: 0.3029 - val_accuracy: 0.9600\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2844 - accuracy: 0.9799 - val_loss: 0.2974 - val_accuracy: 0.9600\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2998 - accuracy: 0.9732 - val_loss: 0.2908 - val_accuracy: 0.9600\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2873 - accuracy: 0.9866 - val_loss: 0.2837 - val_accuracy: 0.9600\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2796 - accuracy: 0.9933 - val_loss: 0.2767 - val_accuracy: 0.9600\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2710 - accuracy: 0.9866 - val_loss: 0.2809 - val_accuracy: 0.9800\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2765 - accuracy: 0.9732 - val_loss: 0.2970 - val_accuracy: 0.9600\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2668 - accuracy: 0.9799 - val_loss: 0.3007 - val_accuracy: 0.9600\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2795 - accuracy: 0.9866 - val_loss: 0.3009 - val_accuracy: 0.9600\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2588 - accuracy: 0.9866 - val_loss: 0.3030 - val_accuracy: 0.9600\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2464 - accuracy: 0.9866 - val_loss: 0.2957 - val_accuracy: 0.9600\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2547 - accuracy: 0.9799 - val_loss: 0.2771 - val_accuracy: 0.9600\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2269 - accuracy: 0.9933 - val_loss: 0.2751 - val_accuracy: 0.9600\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2598 - accuracy: 0.9866 - val_loss: 0.2767 - val_accuracy: 0.9600\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2308 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9600\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2357 - accuracy: 0.9866 - val_loss: 0.2880 - val_accuracy: 0.9600\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2659 - accuracy: 0.9799 - val_loss: 0.2869 - val_accuracy: 0.9600\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2335 - accuracy: 0.9866 - val_loss: 0.2698 - val_accuracy: 0.9600\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2452 - accuracy: 0.9732 - val_loss: 0.2534 - val_accuracy: 0.9600\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2358 - accuracy: 0.9799 - val_loss: 0.2509 - val_accuracy: 0.9600\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2141 - accuracy: 0.9866 - val_loss: 0.2597 - val_accuracy: 0.9600\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2027 - accuracy: 0.9933 - val_loss: 0.2666 - val_accuracy: 0.9600\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2011 - accuracy: 1.0000 - val_loss: 0.2753 - val_accuracy: 0.9600\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2109 - accuracy: 0.9933 - val_loss: 0.2841 - val_accuracy: 0.9600\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2029 - accuracy: 0.9933 - val_loss: 0.2917 - val_accuracy: 0.9600\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2176 - accuracy: 0.9866 - val_loss: 0.2871 - val_accuracy: 0.9600\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2397 - accuracy: 0.9866 - val_loss: 0.2702 - val_accuracy: 0.9600\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2105 - accuracy: 0.9933 - val_loss: 0.2562 - val_accuracy: 0.9600\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2142 - accuracy: 0.9866 - val_loss: 0.2475 - val_accuracy: 0.9600\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2095 - accuracy: 0.9866 - val_loss: 0.2507 - val_accuracy: 0.9600\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2244 - accuracy: 0.9933 - val_loss: 0.2522 - val_accuracy: 0.9600\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2008 - accuracy: 0.9866 - val_loss: 0.2471 - val_accuracy: 0.9600\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1915 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.9600\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1851 - accuracy: 0.9933 - val_loss: 0.2607 - val_accuracy: 0.9600\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.2004 - accuracy: 0.9866 - val_loss: 0.2647 - val_accuracy: 0.9600\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1907 - accuracy: 0.9933 - val_loss: 0.2607 - val_accuracy: 0.9600\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2111 - accuracy: 0.9799 - val_loss: 0.2539 - val_accuracy: 0.9600\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.9866 - val_loss: 0.2390 - val_accuracy: 0.9600\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2113 - accuracy: 0.9732 - val_loss: 0.2281 - val_accuracy: 0.9600\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2008 - accuracy: 0.9933 - val_loss: 0.2266 - val_accuracy: 0.9600\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1957 - accuracy: 0.9866 - val_loss: 0.2226 - val_accuracy: 0.9600\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1977 - accuracy: 0.9799 - val_loss: 0.2196 - val_accuracy: 0.9600\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1839 - accuracy: 0.9866 - val_loss: 0.2240 - val_accuracy: 0.9600\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1781 - accuracy: 0.9933 - val_loss: 0.2287 - val_accuracy: 0.9600\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1713 - accuracy: 0.9933 - val_loss: 0.2236 - val_accuracy: 0.9600\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1753 - accuracy: 0.9933 - val_loss: 0.2235 - val_accuracy: 0.9600\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1714 - accuracy: 0.9933 - val_loss: 0.2210 - val_accuracy: 0.9600\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1781 - accuracy: 0.9866 - val_loss: 0.2203 - val_accuracy: 0.9600\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1658 - accuracy: 1.0000 - val_loss: 0.2122 - val_accuracy: 0.9600\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1749 - accuracy: 0.9933 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1676 - accuracy: 1.0000 - val_loss: 0.2087 - val_accuracy: 0.9600\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.1973 - accuracy: 0.9866 - val_loss: 0.2161 - val_accuracy: 0.9600\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.1526 - accuracy: 0.9933 - val_loss: 0.2232 - val_accuracy: 0.9600\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1666 - accuracy: 0.9933 - val_loss: 0.2128 - val_accuracy: 0.9600\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1567 - accuracy: 0.9933 - val_loss: 0.2011 - val_accuracy: 0.9600\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1614 - accuracy: 0.9933 - val_loss: 0.1953 - val_accuracy: 0.9600\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1722 - accuracy: 0.9866 - val_loss: 0.1941 - val_accuracy: 0.9600\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9600\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1471 - accuracy: 0.9933 - val_loss: 0.2099 - val_accuracy: 0.9600\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1417 - accuracy: 1.0000 - val_loss: 0.2193 - val_accuracy: 0.9600\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 0.1427 - accuracy: 1.0000 - val_loss: 0.2244 - val_accuracy: 0.9600\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1499 - accuracy: 0.9933 - val_loss: 0.2108 - val_accuracy: 0.9600\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.1485 - accuracy: 0.9933 - val_loss: 0.2008 - val_accuracy: 0.9600\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1385 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 0.9600\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1488 - accuracy: 0.9933 - val_loss: 0.2166 - val_accuracy: 0.9600\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1344 - accuracy: 1.0000 - val_loss: 0.2132 - val_accuracy: 0.9600\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1486 - accuracy: 0.9866 - val_loss: 0.2050 - val_accuracy: 0.9600\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=300,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 265ms/step\n",
      "HASIL : [[5.5836010e-01 3.0170161e-01 6.6796239e-03 1.1631828e-02 4.1995905e-04\n",
      "  1.7095628e-04 1.2103600e-01]]\n"
     ]
    }
   ],
   "source": [
    "hasil = model.predict([[2,0,1,1,1,2,1,0,1,1,2,0,1,2,1,0,0,1,1,2,1,1,0,1,0]])\n",
    "print(f\"HASIL : {hasil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath=\"../src/model/sector_classification_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bangkit_Capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
